{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation with Anthropic Claude 3, Amazon Bedrock and Llama-index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook we will show you how to use Llama-index to generate text with Anthropic Claude 3 and Amazon Bedrock \n",
    "\n",
    "\n",
    "The prompt used in this example is called a zero-shot prompt because we are not providing any examples of text other than the prompt.\n",
    "\n",
    "\n",
    "#### Use case\n",
    "\n",
    "To demonstrate the text generation capability of Anthropic Claude 3, let's take the use case of email generation.\n",
    "\n",
    "\n",
    "#### Persona\n",
    "You are Bob a Customer Service Manager at AnyCompany and some of your customers are not happy with the customer service and are providing negative feedbacks on the service provided by customer support engineers. Now, you would like to respond to those customers humbly aplogizing for the poor service and regain trust. You need the help of an LLM to generate a bulk of emails for you which are human friendly and personalized to the customer's sentiment from previous email correspondence.\n",
    "\n",
    "#### Implementation\n",
    "To fulfill this use case, in this notebook we will show how to generate an email with a thank you note based on the customer's previous email.We will use the Anthropic Claude 3 Sonnet Foundation model using the Amazon Bedrock and Llama-index. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python 3.10\n",
    "\n",
    "⚠  For this lab we need to run the notebook based on a Python 3.10 runtime. ⚠\n",
    "\n",
    "\n",
    "## Installation\n",
    "\n",
    "To run this notebook you would need to install dependencies - llama-index and llama-index-llms-bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%pip install llama-index --force-reinstall --quiet\n",
    "%pip install llama-index-llms-bedrock --force-reinstall --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Restart\n",
    "\n",
    "Restart the kernel with the updated packages that are installed through the dependencies above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup \n",
    "\n",
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.llms.bedrock import Bedrock\n",
    "from llama_index.core.llms import ChatMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Initiate Bedrock Runtime through llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_id = 'anthropic.claude-3-sonnet-20240229-v1:0' # change this to use a different version from the model provider\n",
    "\n",
    "llm = Bedrock(\n",
    "   model=model_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Invocation and Response Generation\n",
    "\n",
    "Invoke the model and visualize the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a helpful assistant\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"Write an email from Bob, Customer Service Manager, to the customer John Doe who provided negative feedback on the service provided by our customer support engineer\"),\n",
    "]\n",
    "\n",
    "# Invoke\n",
    "response = llm.chat(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "You have now experimented with using `llama-index` SDK to get an exposure to Anthropic Claude 3 and Amazon Bedrock. Using llama-index you have generated an email responding to a customer due to their negative feedback.\n",
    "\n",
    "### Take aways\n",
    "- Adapt this notebook to experiment with different Claude 3 models available through Amazon Bedrock. \n",
    "- Change the prompts to your specific usecase and evaluate the output of different models.\n",
    "- Play with the token length to understand the latency and responsiveness of the service.\n",
    "- Apply different prompt engineering principles to get better outputs.\n",
    "\n",
    "## Thank You"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
